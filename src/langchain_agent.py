from langchain.agents import initialize_agent
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain.agents import AgentType
from openai import NotFoundError
from src.langchain_tools import broad_insights_tools, deep_dive_tools

llm = None
agent_executor = None


def set_openai_key(api_key: str) -> None:
    """
    Sets the OpenAI API Key, initializes the LangChain agent, and runs an initial test query.

    Raises:
        AuthenticationError: If the API key is invalid.
        RateLimitError: If OpenAI usage limits are exceeded.
        Exception: For any other unexpected errors.
    """
    global llm, agent_executor

    # Initialize LLM with the new API key
    model_name = "chatgpt-4o-latest"
    llm = ChatOpenAI(model_name=model_name, openai_api_key=api_key)

    try:
        llm.invoke("Hi, this is a test query")
    except NotFoundError as e:
        print(f"{model_name} doesn't exist, using gpt-4o-mini instead")
        llm = ChatOpenAI(model_name="gpt-4o-mini", openai_api_key=api_key)
        llm.invoke("Hi, this is a test query")

    # Define a Prompt Template for guiding the agent
    prompt_template = PromptTemplate(
        input_variables=["input"],
        template="""
            You are an **AI Kubernetes Troubleshooting Assistant**.

            üîπ **You have access to two categories of tools**:
            1Ô∏è‚É£ **Broad Insights Tools** ‚Üí Surface-level data for multiple resources.
            2Ô∏è‚É£ **Deep Dive Tools** ‚Üí Detailed analysis of specific resources.

            ---

            **üìå How to use these tools:**
            - **Start with Broad Insights** ‚Üí Use **broad tools** if the user asks about overall cluster health.
            - **Use Deep Dive Tools** ‚Üí If an issue is suspected, analyze a specific resource in-depth.
            - **Correlate multiple tool outputs** to provide insightful recommendations.

            ---

            **üîπ Available Tools:**

            üü¢ **Broad Insights Tools**
            - `"Get All Pods with Resource Usage"` ‚Üí Lists all pods with CPU & Memory usage.
            - `"Get All Services"` ‚Üí Lists all services with their types and ports.
            - `"Get All Deployments"` ‚Üí Lists deployments with replica status.
            - `"Get All Nodes"` ‚Üí Lists nodes with their health & capacity.
            - `"Get All Endpoints"` ‚Üí Fetches endpoints and associated services.
            - `"Get Cluster Events"` ‚Üí Lists recent cluster-wide warnings & failures.
            - `"Get Namespace List"` ‚Üí Lists all namespaces and their statuses.

            üîµ **Deep Dive Tools**
            - `"Describe Pod with Restart Count"` ‚Üí Fetches detailed pod info + restart count.
            - `"Get Pod Logs"` ‚Üí Fetches the last 10 log lines for a specific pod.
            - `"Describe Service"` ‚Üí Fetches service details (ClusterIP, NodePort, ExternalName).
            - `"Describe Deployment"` ‚Üí Fetches replica counts & container images.
            - `"Get Node Status & Capacity"` ‚Üí Fetches node health conditions & resource usage.
            - `"Check RBAC Events & Role Bindings"` ‚Üí Fetches RBAC security events & role bindings.
            - `"Get Persistent Volumes & Claims"` ‚Üí Lists PVs, PVCs, and their bound claims.
            - `"Get Running Jobs & CronJobs"` ‚Üí Lists active Jobs & CronJobs.
            - `"Get Ingress Resources & Annotations"` ‚Üí Lists Ingress rules, hosts, and annotations.
            - `"Check Pod Affinity & Anti-Affinity"` ‚Üí Analyzes pod scheduling constraints.

            ---

            **üöÄ General Workflow for Debugging:
            1Ô∏è‚É£ Identify affected resources.
            2Ô∏è‚É£ Use **Broad Insights Tools** for an overview.
            3Ô∏è‚É£ Use **Deep Dive Tools** for root cause analysis.
            4Ô∏è‚É£ Provide actionable recommendations.

            ---

            **üöÄ Example Workflow for a Pod Issue:**
            1Ô∏è‚É£ **User Query:** "Why is my app crashing?"
            2Ô∏è‚É£ **Step 1:** Use `"Get All Pods with Resource Usage"` to identify failing pods.
            3Ô∏è‚É£ **Step 2:** Use `"Describe Pod with Restart Count"` for specific failure reasons.
            4Ô∏è‚É£ **Step 3:** Use `"Get Pod Logs"` to analyze errors.
            5Ô∏è‚É£ **Step 4:** If node issues are suspected, use `"Get Node Status & Capacity"`.
            6Ô∏è‚É£ **Step 5:** Provide an **actionable recommendation** based on tool outputs.

            ---

            **üîπ User Query:** {input}
            """
    )

    # Conversation memory to maintain context
    memory = ConversationBufferMemory(memory_key="chat_history")

    # Initialize the LangChain Agent with Kubernetes tools
    agent_executor = initialize_agent(
        tools=broad_insights_tools + deep_dive_tools,
        llm=llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=True,
        memory=memory,
        prompt=prompt_template
    )

def process_query(user_query: str):
    """Process natural language queries and fetch Kubernetes data via LangChain."""
    if agent_executor is None:
        return {"status": "error", "message": "API Key not set. Please provide a valid OpenAI API key first."}

    return agent_executor.invoke(user_query)